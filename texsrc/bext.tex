\chapter{RISC-V Bitmanip Extension}
\label{bext}

In the proposals provided in this chapter, the C code examples are for
illustration purposes only. They are not optimal implementations, but are
intended to specify the desired functionality.
% See Section~\ref{fastc} for fast C code for use in emulators.

The final standard will likely define a range of Z-extensions for different bit
manipulation instructions, with the ``B'' extension itself being a mix of
instructions from those Z-extensions. It is unclear as of yet what this will
look like exactly, but it will probably look something like this:

\begin{center}
\begin{tikzpicture}
 \node (clz) { \texttt{clz, ctz, pcnt} };
 \node (slo) [below=0.5cm of clz.west,anchor=west] { \texttt{slo[i], sro[i]} };
 \node (min) [below=0.5cm of slo.west,anchor=west] { \texttt{min[u], max[u]} };
 \node (addwu) [below=0.5cm of min.west,anchor=west] { \texttt{add[i]wu, subwu} };
 \node (adduw) [below=0.5cm of addwu.west,anchor=west] { \texttt{addu.w, subu.w} };
 \node (slliuw) [below=0.5cm of adduw.west,anchor=west] { \texttt{slliu.w} };

 \node (sbset) [right=4.5cm of clz.west,anchor=west] { \texttt{sbset} };
 \node (sbclr) [right=4.5cm of slo.west,anchor=west] { \texttt{sbclr} };
 \node (sbinv) [right=4.5cm of min.west,anchor=west] { \texttt{sbinv} };
 \node (sbext) [right=4.5cm of addwu.west,anchor=west] { \texttt{sbext} };

 \node (andn) [below=1.0cm of slliuw.west,anchor=west] { \texttt{andn, orn} };
 \node (xnor) [below=0.5cm of andn.west,anchor=west] { \texttt{xnor, pack} };
 \node (rol) [below=0.5cm of xnor.west,anchor=west] { \texttt{rol, ror[i]} };
 \node (rev8) [below=0.5cm of rol.west,anchor=west] { \texttt{rev8, rev} };
 \node (revp) [right=4.0cm of rev8.west,anchor=west] { \texttt{rev.p} };
 \node (grev) [right=6.5cm of rev8.west,anchor=west] { \texttt{grev[i]} };

 \node (zip) [below=1.0cm of rev8.west,anchor=west] { \texttt{zip, unzip, zip.n} };
 \node (shuffle) [right=6.5cm of zip.west,anchor=west] { \texttt{shfl[i], unshfl[i]} };

 \node (bext) [below=1.0cm of zip.west,anchor=west] { \texttt{bext, bdep} };

 \node (clmul) [below=1.0cm of bext.west,anchor=west] { \texttt{clmul[hr]} };

 \node (bmatxor) [right=3.5cm of bext.west,anchor=west] { \texttt{bmat[x]or} };
 \node (bmatflip) [below=0.45cm of bmatxor.west,anchor=west] { \texttt{bmatflip} };

 \node (crc32) [below=1.0cm of clmul.west,anchor=west] { \texttt{crc32.[bhwd]} };
 \node (crc32c) [below=0.5cm of crc32.west,anchor=west] { \texttt{crc32c.[bhwd]} };

 \node (cmov) [right=3.5cm of clmul.west,anchor=north west] { \texttt{cmov, cmix} };
 \node (fsl) [below=0.40cm of cmov.west,anchor=west] { \texttt{fsl, fsr[i]} };

 \node (bfxp) [right=3.5cm of crc32c.west,anchor=west] { \texttt{bfxp[u]} };

 \begin{scope}[on background layer]
   \node (B) at ($ (clz.north west) + (0,+0.2cm) $) [above right, text=gray] { \textbf{B$^?$} };
   \draw [draw=black, fill=gray, opacity=0.2] ($ (clz.north west) + (0,+0.2cm) $) |- coordinate (A) ($ (clmul.south west) + (3.15cm,-0.2cm) $) coordinate (B)
     |- ($ (zip.south west) + (6.0cm,-0.2cm) $) |- ($ (clz.north west) + (0,+0.2cm) $);

   \draw [draw=black, dashed, opacity=0.2] (A) |- ($ (crc32c.south) + (0,-0.2cm) $) -| (B);

   \draw [draw=black, dashed, opacity=0.2] ($ (slliuw.west) + (6.0cm,0) $) -| coordinate (A) ($ (shuffle.east) + (+0.2cm,0) $)
     |- ($ (cmov.north west) + (-0.35cm,+0.12cm) $);

   \node (B) at ($ (A) + (0,0) $) [above left, text=gray, opacity=0.5] { \textbf{B$^?$} };

   \node (bb) at ($ (clz.west) + (-0.5cm,0) $) [left, text=red] { \textbf{Zbb$^?$} };
   \node (bbase) [below=-0.1cm of bb.south east,anchor=north east] { (base) };
   \draw [draw=black, fill=red, opacity=0.2] ($ (clz.north west) + (-0.5cm,0) $) rectangle ($ (rev8.south west) + (3.5cm,0) $);

   \node (bs) at ($ (sbset.west) + (2.0cm,0) $) [right, text=blue] { \textbf{Zbs} };
   \node (bsingle) [below=-0.1cm of bs.south west,anchor=north west] { (single bit) };
   \draw [draw=black, fill=blue, opacity=0.2] ($ (sbset.north west) + (-0.2cm,0) $) rectangle ($ (sbext.south west) + (2.0cm,0) $);

   \node (bp) at ($ (andn.west) + (6.5cm,0) $) [right, text=blue] { \textbf{Zbp} };
   \node (bperm) [below=-0.2cm of bp.south west,anchor=north west] { (bit permutation) };
   \draw [draw=black, fill=blue, opacity=0.2] ($ (andn.north west) + (-0.2cm,0) $) |- ($ (shuffle.south east) + (0,0) $)
     |- ($ (revp.north west) + (2.5cm,0.2cm) $) |- ($ (andn.north west) + (-0.2cm,0) $);

   \node (be) at ($ (bext.west) + (-0.5cm,0) $) [left, text=red] { \textbf{Zbe} };
   \draw [draw=black, fill=red, opacity=0.2] ($ (bext.north west) + (-0.5cm,0) $) rectangle ($ (bext.south west) + (3.0cm,0) $);

   \node (bm) at ($ (bmatxor.west) + (3.0cm,0) $) [right, text=blue] { \textbf{Zbm} };
   \node (bmatrix) [below=-0.1cm of bm.south west,anchor=north west] { (bit matrix) };
   \draw [draw=black, fill=blue, opacity=0.2] ($ (bmatxor.north west) + (-0.2cm,0) $) rectangle ($ (bmatflip.south west) + (3.0cm,0) $);

   \node (bc) at ($ (clmul.west) + (-0.5cm,0) $) [left, text=red] { \textbf{Zbc} };
   \draw [draw=black, fill=red, opacity=0.2] ($ (clmul.north west) + (-0.5cm,0) $) rectangle ($ (clmul.south west) + (3.0cm,0) $);

   \node (br) at ($ (crc32.west) + (-0.5cm,0) $) [left, text=blue] { \textbf{Zbr} };
   \draw [draw=black, fill=blue, opacity=0.2] ($ (crc32.north west) + (-0.5cm,0) $) rectangle ($ (crc32c.south west) + (3.0cm,0) $);

   \node (bt) at ($ (cmov.west) + (3.0cm,0) $) [right, text=red] { \textbf{Zbt} };
   \node (bternary) [below=-0.1cm of bt.south west,anchor=north west] { (ternary) };
   \draw [draw=black, fill=red, opacity=0.2] ($ (cmov.north west) + (-0.2cm,0) $) rectangle ($ (fsl.south west) + (3.0cm,0) $);

   \node (bt) at ($ (bfxp.west) + (3.0cm,0) $) [right, text=gray] { \textbf{Zbf} };
   \draw [draw=black, fill=gray, opacity=0.1] ($ (bfxp.north west) + (-0.2cm,0) $) rectangle ($ (bfxp.south west) + (3.0cm,0) $);
 \end{scope}
\end{tikzpicture}
\end{center}

The main open questions of course relate to what should and shouldn't be
included in ``B'', and what should or shouldn't be included in ``Zbb''.
These decisions will be informed in big part by evaluations of the cost and
added value for the individual instructions.

The main open questions are:
\begin{itemize}
\item Should {\tt clmul[hr]} be included in ``B'', or {\tt crc32.[bhwd]/crc32c.[bhwd]}, or neither, or both?
\item Should ``Zbe'' be included in ``B''? Should ``Zbm be included in ``B''?
\item Which ``Zbp'' pseudo-ops should be included in ``B''? Which in ``Zbb''? Should ``Zbp'' be included in ``B'' as a whole?
\end{itemize}

For the purpose of tool-chain development ``B'' is currently everything (excluding ``Zbf'').

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Basic bit manipulation instructions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Count Leading/Trailing Zeros (\texttt{clz, ctz})}

\begin{rvb}
  RV32, RV64:
    clz rd, rs
    ctz rd, rs

  RV64 only:
    clzw rd, rs
    ctzw rd, rs
\end{rvb}

The {\tt clz} operation counts the number of 0 bits at the MSB end of the
argument.  That is, the number of 0 bits before the first 1 bit counting from
the most significant bit. If the input is 0, the output is XLEN. If the input
is -1, the output is 0.

The {\tt ctz} operation counts the number of 0 bits at the LSB end of the
argument. If the input is 0, the output is XLEN. If the input is -1, the
output is 0.

\input{bextcref-clz-ctz}

The expression {\tt XLEN-1-clz(x)} evaluates to the index of the most significant
set bit, also known as integer base-2 logarithm, or -1 if {\tt x} is zero.

% \subsection{References}
%
% https://en.wikipedia.org/wiki/Find\_first\_set\#CLZ
%
% https://fgiesen.wordpress.com/2013/10/18/bit-scanning-equivalencies/

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Count Bits Set (\texttt{pcnt})}

\begin{rvb}
  RV32, RV64:
    pcnt rd, rs

  RV64 only:
    pcntw rd, rs
\end{rvb}

This instruction counts the number of 1 bits in a register. This operations is known as
population count, popcount, sideways sum, bit summation, or Hamming weight.~\cite{HammingWeight,Warren12}

\input{bextcref-pcnt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Logic-with-negate (\texttt{andn}, \texttt{orn}, \texttt{xnor})}

\begin{rvb}
  RV32, RV64:
    andn rd, rs1, rs2
    orn  rd, rs1, rs2
    xnor rd, rs1, rs2
\end{rvb}

This instructions implement AND, OR, and XOR with the 2nd arument inverted.

\input{bextcref-andn}

This can use the existing inverter on rs2 in the ALU that's already there to
implement subtract.

Among other things, those instructions allow implementing the ``trailing bit
manipulation'' code patterns in two instructions each. For example, {\tt (x -
1) \& \textasciitilde{}x} produces a mask from trailing zero bits in {\tt x}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Pack two XLEN/2 words in one register (\texttt{pack})}

\begin{rvb}
  RV32, RV64:
    pack rd, rs1, rs2

  RV64 only:
    packw rd, rs1, rs2
\end{rvb}

This instruction packs the XLEN/2-bit lower halves of rs1 and rs2 into
rd, with rs1 in the lower half and rs2 in the upper half.

\input{bextcref-pack}

Applications include XLEN/2-bit funnel shifts, zero-extend XLEN/2 bit values, duplicate the lower
XLEN/2 bits (e.g. for mask creation), and loading unsigned 32 constants on RV64.

\begin{minipage}{\linewidth}
\begin{verbatim}
  ; Load 0xffff0000ffff0000 on RV64
  lui rd, 0xffff0
  pack rd, rd, rd
\end{verbatim}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{verbatim}
  ; Same as FSLW on RV64
  pack rd, rs1, rs3
  rol rd, rd, rs2
  addiw rd, rd, 0
\end{verbatim}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{verbatim}
  ; Clear the upper half of rd
  pack rd, rd, zero
\end{verbatim}
\end{minipage}

Paired with {\tt shfli/unshfli} and the other bit permutation instructions,
pack can interleave arbitrary power-of-two chunks of {\tt rs1} and {\tt rs2}. For
example, interleaving the bytes in the lower halves of {\tt rs1} and {\tt rs2}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  pack rd, rs1, rs2
  zip8 rd, rd
\end{verbatim}
\end{minipage}

{\tt pack} is most commonly used to zero-extend words $<$XLEN.
For this purpose we define the following assembler pseudo-ops:

\begin{minipage}{\linewidth}
\begin{verbatim}
  RV32:
    zext.b rd, rs   ->    andi  rd, rs, 255
    zext.h rd, rs   ->    pack  rd, rs, zero

  RV64:
    zext.b rd, rs   ->    andi  rd, rs, 255
    zext.h rd, rs   ->    packw rd, rs, zero
    zext.w rd, rs   ->    pack  rd, rs, zero

  RV128:.
    zext.b rd, rs   ->    andi  rd, rs, 255
    zext.h rd, rs   ->    packw rd, rs, zero
    zext.w rd, rs   ->    packd rd, rs, zero
    zext.d rd, rs   ->    pack  rd, rs, zero
\end{verbatim}
\end{minipage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Min/max instructions (\texttt{min, max, minu, maxu})}

\begin{rvb}
  RV32, RV64:
    min  rd, rs1, rs2
    max  rd, rs1, rs2
    minu rd, rs1, rs2
    maxu rd, rs1, rs2
\end{rvb}

We define 4 R-type instructions \texttt{min, max, minu, maxu} with the
following semantics:

\input{bextcref-minmax}

Code that performs saturated arithmetic on a word size $<$ \texttt{XLEN} needs to perform
min/max operations frequently. A simple way of performing those operations without branching
can benefit those programs.

SAT solvers spend a lot of time calculating the absolute value of a signed
integer due to the way CNF literals are commonly encoded~\cite{BiereComm}. With
\texttt{max} (or \texttt{minu}) this is a two-instruction operation:

\begin{minipage}{\linewidth}
\begin{verbatim}
  neg a1, a0
  max a0, a0, a1
\end{verbatim}
\end{minipage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Single-bit instructions (\texttt{sbset, sbclr, sbinv, sbext})}

\begin{rvb}
  RV32, RV64:
    sbset  rd, rs1, rs2
    sbclr  rd, rs1, rs2
    sbinv  rd, rs1, rs2
    sbext  rd, rs1, rs2
    sbseti rd, rs1, imm
    sbclri rd, rs1, imm
    sbinvi rd, rs1, imm
    sbexti rd, rs1, imm

  RV64:
    sbsetw  rd, rs1, rs2
    sbclrw  rd, rs1, rs2
    sbinvw  rd, rs1, rs2
    sbextw  rd, rs1, rs2
    sbsetiw rd, rs1, imm
    sbclriw rd, rs1, imm
    sbinviw rd, rs1, imm
\end{rvb}

We define 4 single-bit instructions \texttt{sbset} (set), \texttt{sbclr} (clear),
\texttt{sbinv} (invert), and \texttt{sbext} (extract), and their immediate-variants,
with the following semantics:

\input{bextcref-sbx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Shift Ones (Left/Right) (\texttt{slo,\ sloi,\ sro,\ sroi})}

\begin{rvb}
  RV32, RV64:
    slo  rd, rs1, rs2
    sro  rd, rs1, rs2
    sloi rd, rs1, imm
    sroi rd, rs1, imm

  RV64 only:
    slow  rd, rs1, rs2
    srow  rd, rs1, rs2
    sloiw rd, rs1, imm
    sroiw rd, rs1, imm
\end{rvb}

These instructions are similar to shift-logical operations from the base
spec, except instead of shifting in zeros, they shift in ones.

\input{bextcref-sxo}

ISAs with flag registers often have a "Shift in Carry" or "Rotate through Carry" instruction.
Arguably a "Shift Ones" is an equivalent on an ISA like RISC-V that avoids such flag registers.

The main application for the Shift Ones instruction is mask generation.

When implementing this circuit, the only change in the ALU over a
standard logical shift is that the value shifted in is not zero, but is
a 1-bit register value that has been forwarded from the high bit of the
instruction decode. This creates the desired behavior on both logical
zero-shifts and logical ones-shifts.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bit permutation instructions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Rotate (Left/Right) (\texttt{rol,\ ror,\ rori})}

\begin{rvb}
  RV32, RV64:
    ror  rd, rs1, rs2
    rol  rd, rs1, rs2
    rori rd, rs1, imm

  RV64 only:
    rorw  rd, rs1, rs2
    rolw  rd, rs1, rs2
    roriw rd, rs1, imm
\end{rvb}

These instructions are similar to shift-logical operations from the base
spec, except they shift in the values from the opposite side of the
register, in order. This is also called `circular shift'.

\input{bextcref-rox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
\begin{center}
\input{bextcref-printperm-ror}
\end{center}
\caption{\texttt{ror} permutation network}
\label{permnet-ror}
\end{figure}

\subsection{Generalized Reverse (\texttt{grev}, \texttt{grevi}, \texttt{rev})}
\label{grev}

\begin{rvb}
  RV32, RV64:
    grev  rd, rs1, rs2
    grevi rd, rs1, imm

  RV64 only:
    grevw  rd, rs1, rs2
    greviw rd, rs1, imm
\end{rvb}

This instruction provides a single hardware instruction that can implement all
of byte-order swap, bitwise reversal, short-order-swap, word-order-swap
(RV64), nibble-order swap, bitwise reversal in a byte, etc, all from a single
hardware instruction.

The Generalized Reverse (GREV) operation iteratively checks each bit $i$ in the
2nd argument from $i=0$ to $log2(\textrm{XLEN})-1$, and if the corresponding bit is
set, swaps each adjacent pair of $2^i$ bits.

\begin{figure}[t]
\begin{center}
\input{bextcref-printperm-grev}
\end{center}
\caption{\texttt{grev} permutation network}
\label{permnet-grev}
\end{figure}

\input{bextcref-grev}

The above pattern should be intuitive to understand in order to extend
this definition in an obvious manner for RV128.

\begin{table}[h]
\begin{small}
\begin{center}
\begin{tabular}{r l p{0.5in} r l p{0.3in} r l}

\multicolumn{2}{c}{RV32} & &
\multicolumn{5}{c}{RV64} \\

\cline{1-2}
\cline{4-8}

\multicolumn{1}{c}{shamt} & Instruction & &
\multicolumn{1}{c}{shamt} & Instruction & &
\multicolumn{1}{c}{shamt} & Instruction \\

\cline{1-2}
\cline{4-5}
\cline{7-8}

 0: 00000 & ---           &   &  0: 000000 & ---           &   & 32: 100000 & {\tt rev32} \\
 1: 00001 & {\tt rev.p}   &   &  1: 000001 & {\tt rev.p}   &   & 33: 100001 & ---         \\
 2: 00010 & {\tt rev2.n}  &   &  2: 000010 & {\tt rev2.n}  &   & 34: 100010 & ---         \\
 3: 00011 & {\tt rev.n}   &   &  3: 000011 & {\tt rev.n}   &   & 35: 100011 & ---         \\
 4: 00100 & {\tt rev4.b}  &   &  4: 000100 & {\tt rev4.b}  &   & 36: 100100 & ---         \\
 5: 00101 & ---           &   &  5: 000101 & ---           &   & 37: 100101 & ---         \\
 6: 00110 & {\tt rev2.b}  &   &  6: 000110 & {\tt rev2.b}  &   & 38: 100110 & ---         \\
 7: 00111 & {\tt rev.b}   &   &  7: 000111 & {\tt rev.b}   &   & 39: 100111 & ---         \\

\cline{1-2}
\cline{4-5}
\cline{7-8}

 8: 01000 & {\tt rev8.h}  &   &  8: 001000 & {\tt rev8.h}  &   & 40: 101000 & ---         \\
 9: 01001 & ---           &   &  9: 001001 & ---           &   & 41: 101001 & ---         \\
10: 01010 & ---           &   & 10: 001010 & ---           &   & 42: 101010 & ---         \\
11: 01011 & ---           &   & 11: 001011 & ---           &   & 43: 101011 & ---         \\
12: 01100 & {\tt rev4.h}  &   & 12: 001100 & {\tt rev4.h}  &   & 44: 101100 & ---         \\
13: 01101 & ---           &   & 13: 001101 & ---           &   & 45: 101101 & ---         \\
14: 01110 & {\tt rev2.h}  &   & 14: 001110 & {\tt rev2.h}  &   & 46: 101110 & ---         \\
15: 01111 & {\tt rev.h}   &   & 15: 001111 & {\tt rev.h}   &   & 47: 101111 & ---         \\

\cline{1-2}
\cline{4-5}
\cline{7-8}

16: 10000 & {\tt rev16}   &   & 16: 010000 & {\tt rev16.w} &   & 48: 110000 & {\tt rev16} \\
17: 10001 & ---           &   & 17: 010001 & ---           &   & 49: 110001 & ---         \\
18: 10010 & ---           &   & 18: 010010 & ---           &   & 50: 110010 & ---         \\
19: 10011 & ---           &   & 19: 010011 & ---           &   & 51: 110011 & ---         \\
20: 10100 & ---           &   & 20: 010100 & ---           &   & 52: 110100 & ---         \\
21: 10101 & ---           &   & 21: 010101 & ---           &   & 53: 110101 & ---         \\
22: 10110 & ---           &   & 22: 010110 & ---           &   & 54: 110110 & ---         \\
23: 10111 & ---           &   & 23: 010111 & ---           &   & 55: 110111 & ---         \\

\cline{1-2}
\cline{4-5}
\cline{7-8}

24: 11000 & {\tt rev8}    &   & 24: 011000 & {\tt rev8.w}  &   & 56: 111000 & {\tt rev8}  \\
25: 11001 & ---           &   & 25: 011001 & ---           &   & 57: 111001 & ---         \\
26: 11010 & ---           &   & 26: 011010 & ---           &   & 58: 111010 & ---         \\
27: 11011 & ---           &   & 27: 011011 & ---           &   & 59: 111011 & ---         \\
28: 11100 & {\tt rev4}    &   & 28: 011100 & {\tt rev4.w}  &   & 60: 111100 & {\tt rev4}  \\
29: 11101 & ---           &   & 29: 011101 & ---           &   & 61: 111101 & ---         \\
30: 11110 & {\tt rev2}    &   & 30: 011110 & {\tt rev2.w}  &   & 62: 111110 & {\tt rev2}  \\
31: 11111 & {\tt rev}     &   & 31: 011111 & {\tt rev.w}   &   & 63: 111111 & {\tt rev}   \\
\end{tabular}
\end{center}
\end{small}
\caption{Pseudo-instructions for {\tt grevi} instruction}
\label{grevi-modes}
\end{table}

The {\tt grev} operation can easily be implemented using a permutation
network with $log_2(\textrm{XLEN})$ stages. Figure~\ref{permnet-ror}
shows the permutation network for {\tt ror} for reference.
Figure~\ref{permnet-grev} shows the permutation network for {\tt grev}.

\texttt{grev} is encoded as standard R-type opcode and \texttt{grevi} is
encoded as standard I-type opcode. \texttt{grev} and \texttt{grevi} can
use the instruction encoding for ``arithmetic shift left''.

Pseudo-instructions are provided for the most common GREVI use-cases. Their names
consist of a prefix and and optional suffix. Each prefix and suffix corresponds
to a bit mask. The GREVI control word is obtained by AND-ing the two masks together.

\begin{center}
\begin{tabular}{lcp{1cm}rc}
Prefix & Mask & & Suffix & Mask \\
\hline
{\tt rev}   & 111111 & &      --- & 111111 \\
{\tt rev2}  & 111110 & & {\tt .w} & 011111 \\
{\tt rev4}  & 111100 & & {\tt .h} & 001111 \\
{\tt rev8}  & 111000 & & {\tt .b} & 000111 \\
{\tt rev16} & 110000 & & {\tt .n} & 000011 \\
{\tt rev32} & 100000 & & {\tt .p} & 000001 \\
\end{tabular}
\end{center}

In other words, the prefix controls the number of zero bits at the LSB end of the
control word, and the suffix controls the number of zeros at the MSB end of the control
word.

{\tt rev8} reverses the order of bytes in a word, thus performs endianness conversion.

% \subsection{References}
%
% Hackers Delight, Chapter 7.1, ``Generalized Bit Reversal'' in
%
% https://books.google.com/books?id=iBNKMspIlqEC\&lpg=PP1\&pg=RA1-SL20-PA2\#v=onepage\&q\&f=false
%
% http://hackersdelight.org/

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Generalized Shuffle (\texttt{shfl}, \texttt{unshfl}, \texttt{shfli}, \texttt{unshfli}, \texttt{zip}, \texttt{unzip})}
\label{gzip}

\begin{rvb}
  RV32, RV64:
    shfl    rd, rs1, rs2
    unshfl  rd, rs1, rs2
    shfli   rd, rs1, imm
    unshfli rd, rs1, imm

  RV64 only:
    shflw    rd, rs1, rs2
    unshflw  rd, rs1, rs2
\end{rvb}

Shuffle is the third bit permutation instruction in the RISC-V Bitmanip
extension, after rotary shift and generalized reverse. It implements a
generalization of the operation commonly known as perfect outer shuffle and its
inverse (shuffle/unshuffle), also known as zip/unzip or interlace/uninterlace.

Bit permutations can be understood as reversible functions on bit indices (i.e.
5 bit functions on RV32 and 6 bit functions on RV64).

\begin{center}
\begin{tabular}{l l}
Operation & Corresponding function on bit indices \\
\hline
Rotate shift & Addition modulo {\rm XLEN} \\
Generalized reverse & XOR with bitmask \\
Generalized shuffle & Bitpermutation \\
\end{tabular}
\end{center}

A generalized (un)shuffle operation has $log_2(\textrm{XLEN})-1$ control bits,
one for each pair of neighbouring bits in a bit index. When the bit is set,
generalized shuffle will swap the two index bits. The {\tt shfl} operation
performs this swaps in MSB-to-LSB order (performing a rotate left shift on
contiguous regions of set control bits), and the {\tt unshfl} operation performs
the swaps in LSB-to-MSB order (performing a rotate right shift on contiguous
regions of set control bits). Combining up to $log_2(\textrm{XLEN})$ of those
{\tt shfl}/{\tt unshfl} operations can implement any bitpermutation on the
bit indices.

The most common type of shuffle/unshuffle operation is one on an immediate
control value that only contains one contiguous region of set bits. We call
those operations zip/unzip and provide pseudo-instructions for them. The naming
scheme for those pseudo-instructions is similar to the naming scheme for the
{\tt grevi} pseudo-instructions.

Shuffle/unshuffle operations that only have individual bits set (not a contiguous
region of two or more bits) are their own inverse.

\begin{table}[h]
\begin{small}
\begin{center}
\begin{tabular}{r c l l}
\multicolumn{1}{c}{shamt} &
\multicolumn{1}{c}{inv} &
Bit index rotations &
Pseudo-Instruction \\

\hline

 0: 0000 & 0 & no-op                            & ---                    \\
    0000 & 1 & no-op                            & ---                    \\
 1: 0001 & 0 & {\tt i[1] -> i[0]}               & {\tt zip.n, unzip.n}   \\
    0001 & 1 & {\it equivalent to 0001 0}       & ---                    \\
 2: 0010 & 0 & {\tt i[2] -> i[1]}               & {\tt zip2.b, unzip2.b} \\
    0010 & 1 & {\it equivalent to 0010 0}       & ---                    \\
 3: 0011 & 0 & {\tt i[2] -> i[0]}               & {\tt zip.b}            \\
    0011 & 1 & {\tt i[2] <- i[0]}               & {\tt unzip.b}          \\

\hline

 4: 0100 & 0 & {\tt i[3] -> i[2]}               & {\tt zip4.h, unzip4.h} \\
    0100 & 1 & {\it equivalent to 0100 0}       & ---                    \\
 5: 0101 & 0 & {\tt i[3] -> i[2], i[1] -> i[0]} & ---                    \\
    0101 & 1 & {\it equivalent to 0101 0}       & ---                    \\
 6: 0110 & 0 & {\tt i[3] -> i[1]}               & {\tt zip2.h}           \\
    0110 & 1 & {\tt i[3] <- i[1]}               & {\tt unzip2.h}         \\
 7: 0111 & 0 & {\tt i[3] -> i[0]}               & {\tt zip.h}            \\
    0111 & 1 & {\tt i[3] <- i[0]}               & {\tt unzip.h}          \\

\hline

 8: 1000 & 0 & {\tt i[4] -> i[3]}               & {\tt zip8, unzip8}     \\
    1000 & 1 & {\it equivalent to 1000 0}       & ---                    \\
 9: 1001 & 0 & {\tt i[4] -> i[3], i[1] -> i[0]} & ---                    \\
    1001 & 1 & {\it equivalent to 1001 0}       & ---                    \\
10: 1010 & 0 & {\tt i[4] -> i[3], i[2] -> i[1]} & ---                    \\
    1010 & 1 & {\it equivalent to 1010 0}       & ---                    \\
11: 1011 & 0 & {\tt i[4] -> i[3], i[2] -> i[0]} & ---                    \\
    1011 & 1 & {\tt i[4] <- i[3], i[2] <- i[0]} & ---                    \\

\hline

12: 1100 & 0 & {\tt i[4] -> i[2]}               & {\tt zip4}             \\
    1100 & 1 & {\tt i[4] <- i[2]}               & {\tt unzip4}           \\
13: 1101 & 0 & {\tt i[4] -> i[2], i[1] -> i[0]} & ---                    \\
    1101 & 1 & {\tt i[4] <- i[2], i[1] <- i[0]} & ---                    \\
14: 1110 & 0 & {\tt i[4] -> i[1]}               & {\tt zip2}             \\
    1110 & 1 & {\tt i[4] <- i[1]}               & {\tt unzip2}           \\
15: 1111 & 0 & {\tt i[4] -> i[0]}               & {\tt zip}              \\
    1111 & 1 & {\tt i[4] <- i[0]}               & {\tt unzip}            \\

\end{tabular}
\end{center}
\end{small}
\caption{RV32 modes and pseudo-instructions for {\tt shfli}/{\tt unshfli} instruction}
\label{gzip32-modes}
\end{table}

\begin{table}[h]
\begin{small}
\begin{center}
\begin{tabular}{r c l p{1in} r c l}
\multicolumn{1}{c}{shamt} &
\multicolumn{1}{c}{inv} &
Pseudo-Instruction & &
\multicolumn{1}{c}{shamt} &
\multicolumn{1}{c}{inv} &
Pseudo-Instruction \\

\cline{1-3}
\cline{5-7}

 0: 00000 & 0 & ---                      &   &   16: 10000 & 0 & {\tt zip16, unzip16}    \\
    00000 & 1 & ---                      &   &       10000 & 1 & ---                     \\
 1: 00001 & 0 & {\tt zip.n, unzip.n}     &   &   17: 10001 & 0 & ---                     \\
    00001 & 1 & ---                      &   &       10001 & 1 & ---                     \\
 2: 00010 & 0 & {\tt zip2.b, unzip2.b}   &   &   18: 10010 & 0 & ---                     \\
    00010 & 1 & ---                      &   &       10010 & 1 & ---                     \\
 3: 00011 & 0 & {\tt zip.b}              &   &   19: 10011 & 0 & ---                     \\
    00011 & 1 & {\tt unzip.b}            &   &       10011 & 1 & ---                     \\

\cline{1-3}
\cline{5-7}

 4: 00100 & 0 & {\tt zip4.h, unzip4.h}   &   &   20: 10100 & 0 & ---                     \\
    00100 & 1 & ---                      &   &       10100 & 1 & ---                     \\
 5: 00101 & 0 & ---                      &   &   21: 10101 & 0 & ---                     \\
    00101 & 1 & ---                      &   &       10101 & 1 & ---                     \\
 6: 00110 & 0 & {\tt zip2.h}             &   &   22: 10110 & 0 & ---                     \\
    00110 & 1 & {\tt unzip2.h}           &   &       10110 & 1 & ---                     \\
 7: 00111 & 0 & {\tt zip.h}              &   &   23: 10111 & 0 & ---                     \\
    00111 & 1 & {\tt unzip.h}            &   &       10111 & 1 & ---                     \\

\cline{1-3}
\cline{5-7}

 8: 01000 & 0 & {\tt zip8.w, unzip8.w}   &   &   24: 11000 & 0 & {\tt zip8}              \\
    01000 & 1 & ---                      &   &       11000 & 1 & {\tt unzip8}            \\
 9: 01001 & 0 & ---                      &   &   25: 11001 & 0 & ---                     \\
    01001 & 1 & ---                      &   &       11001 & 1 & ---                     \\
10: 01010 & 0 & ---                      &   &   26: 11010 & 0 & ---                     \\
    01010 & 1 & ---                      &   &       11010 & 1 & ---                     \\
11: 01011 & 0 & ---                      &   &   27: 11011 & 0 & ---                     \\
    01011 & 1 & ---                      &   &       11011 & 1 & ---                     \\

\cline{1-3}
\cline{5-7}

12: 01100 & 0 & {\tt zip4.w}             &   &   28: 11100 & 0 & {\tt zip4}              \\
    01100 & 1 & {\tt unzip4.w}           &   &       11100 & 1 & {\tt unzip4}            \\
13: 01101 & 0 & ---                      &   &   29: 11101 & 0 & ---                     \\
    01101 & 1 & ---                      &   &       11101 & 1 & ---                     \\
14: 01110 & 0 & {\tt zip2.w}             &   &   30: 11110 & 0 & {\tt zip2}              \\
    01110 & 1 & {\tt unzip2.w}           &   &       11110 & 1 & {\tt unzip2}            \\
15: 01111 & 0 & {\tt zip.w}              &   &   31: 11111 & 0 & {\tt zip}               \\
    01111 & 1 & {\tt unzip.w}            &   &       11111 & 1 & {\tt unzip}             \\

\end{tabular}
\end{center}
\end{small}
\caption{RV64 modes and pseudo-instructions for {\tt shfli}/{\tt unshfli} instruction}
\label{gzip64-modes}
\end{table}

\begin{figure}[t]
\begin{center}
\input{bextcref-printperm-gzip-noflip}
\end{center}
\caption{(un)shuffle permutation network without ``flip'' stages}
\label{permnet-gzip-noflip}
\end{figure}

Like GREV and rotate shift, the (un)shuffle instruction can be implemented using a short
sequence of elementary permutations, that are enabled or disabled by the shamt
bits. But (un)shuffle has one stage fewer than GREV. Thus shfli+unshfli together require
the same amount of encoding space as grevi.

\input{bextcref-gzip32}

Or for RV64:

\input{bextcref-gzip64}

The above pattern should be intuitive to understand in order to extend
this definition in an obvious manner for RV128.

Alternatively (un)shuffle can be implemented in a single network with one more
stage than GREV, with the additional first and last stage executing a
permutation that effectively reverses the order of the inner stages. However,
since the inner stages only mux half of the bits in the word each, a hardware
implementation using this additional ``flip'' stages might actually be more
expensive than simply creating two networks.

\input{bextcref-gzip32-alt}

Figure~\ref{permnet-gzip-flip} shows the (un)shuffle permutation network with
``flip'' stages and Figure~\ref{permnet-gzip-noflip} shows the (un)shuffle
permutation network without ``flip'' stages.

\begin{figure}[t]
\begin{center}
\input{bextcref-printperm-gzip-flip}
\end{center}
\caption{(un)shuffle permutation network with ``flip'' stages}
\label{permnet-gzip-flip}
\end{figure}

The \texttt{zip} instruction with the upper half of its input cleared performs
the commonly needed ``fan-out'' operation. (Equivalent to {\tt bdep} with a
0x55555555 mask.) The \texttt{zip} instruction applied twice fans out the bits
in the lower quarter of the input word by a spacing of 4 bits.

For example, the following code calculates the bitwise prefix sum of the bits
in the lower byte of a 32 bit word on RV32:

\begin{minipage}{\linewidth}
\begin{verbatim}
  andi a0, a0, 0xff
  zip a0, a0
  zip a0, a0
  slli a1, a0, 4
  c.add a0, a1
  slli a1, a0, 8
  c.add a0, a1
  slli a1, a0, 16
  c.add a0, a1
\end{verbatim}
\end{minipage}

The final prefix sum is stored in the 8 nibbles of the {\tt a0} output word.

Similarly, the following code stores the indices of the set bits in the LSB
nibbles of the output word (with the LSB bit having index 1), with the unused
MSB nibbles in the output set to zero:

\begin{minipage}{\linewidth}
\begin{verbatim}
  andi a0, a0, 0xff
  zip a0, a0
  zip a0, a0
  slli a1, a0, 1
  or a0, a0, a1
  slli a1, a0, 2
  or a0, a0, a1
  li a1, 0x87654321
  and a1, a0, a1
  bext a0, a1, a0
\end{verbatim}
\end{minipage}

Other {\tt zip} modes can be used to ``fan-out'' in blocks of 2, 4, 8, or 16 bit.
{\tt zip} can be combined with {\tt grevi} to perform inner shuffles. For example
on RV64:

\begin{minipage}{\linewidth}
\begin{verbatim}
  li a0, 0x0000000012345678
  zip4 t0, a0    ; <- 0x0102030405060708
  rev4.b t1, t0  ; <- 0x1020304050607080
  zip8 t2, a0    ; <- 0x0012003400560078
  rev8.h t3, t2  ; <- 0x1200340056007800
  zip16 t4, a0   ; <- 0x0000123400005678
  rev16.w t5, t4 ; <- 0x1234000056780000
\end{verbatim}
\end{minipage}

Another application for the zip instruction is generating Morton
code~\cite{MortonCode}.

The x86 {\tt PUNPCK[LH]*} MMX/SSE/AVX instructions perform similar operations
as {\tt zip8} and {\tt zip16}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bit Extract/Deposit (\texttt{bext,\ bdep})}

\begin{rvb}
  RV32, RV64:
    bext rd, rs1, rs2
    bdep rd, rs1, rs2

  RV64 only:
    bextw rd, rs1, rs2
    bdepw rd, rs1, rs2
\end{rvb}

This instructions implement the generic bit extract and bit deposit functions.
This operation is also referred to as bit gather/scatter, bit pack/unpack,
parallel extract/deposit, compress/expand, or right\_compress/right\_expand.

\texttt{bext} collects LSB justified bits to rd from rs1 using extract mask in rs2.

\texttt{bdep} writes LSB justified bits from rs1 to rd using deposit mask in rs2.

\input{bextcref-bext}

Implementations may choose to use smaller multi-cycle implementations of
\texttt{bext} and \texttt{bdep}, or even emulate the instructions in software.

Even though multi-cycle \texttt{bext} and \texttt{bdep} often are not fast
enough to outperform algorithms that use sequences of shifts and bit masks,
dedicated instructions for those operations can still be of great advantage in
cases where the mask argument is not constant.

For example, the following code efficiently calculates the index of the tenth
set bit in {\tt a0} using \texttt{bdep}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  li a1, 0x00000200
  bdep a0, a1, a0
  ctz a0, a0
\end{verbatim}
\end{minipage}

For cases with a constant mask an optimizing compiler would decide when to use
\texttt{bext} or \texttt{bdep} based on the optimization profile for the
concrete processor it is optimizing for. This is similar to the decision
whether to use MUL or DIV with a constant, or to perform the same operation
using a longer sequence of much simpler operations.

The \texttt{bext} and \texttt{bdep} instructions are equivalent to the x86 BMI2
instructions PEXT and PDEP. But there is much older prior art. For example, the
soviet BESM-6 mainframe computer, designed and built in the 1960s, had APX/AUX
instructions with almost the same semantics.~\cite{BESM6} (The BESM-6 APX/AUX
instructions packed/unpacked at the MSB end instead of the LSB end. Otherwise
it is the same instruction.)

% \subsection{Justification}
%
% http://svn.clifford.at/handicraft/2017/permsyn/
%
% \subsection{References}
%
% http://programming.sirrida.de/bit\_perm.html\#gather\_scatter
%
% Hackers Delight, Chapter 7.1, ``Compress, Generalized Extract'' in
%
% https://books.google.com/books?id=iBNKMspIlqEC\&lpg=PP1\&pg=RA1-SL20-PA2\#v=onepage\&q\&f=false
%
% http://hackersdelight.org/
%
% https://github.com/cliffordwolf/bextdep
%
% http://palms.ee.princeton.edu/system/files/Hilewitz_JSPS_08.pdf

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Carry-less multiply (\texttt{clmul, clmulh, clmulr})}

\begin{rvb}
  RV32, RV64:
    clmul  rd, rs1, rs2
    clmulh rd, rs1, rs2
    clmulr rd, rs1, rs2

  RV64 only:
    clmulw  rd, rs1, rs2
    clmulhw rd, rs1, rs2
    clmulrw rd, rs1, rs2
\end{rvb}

Calculate the carry-less product~\cite{CarryLessProduct} of the two arguments. \texttt{clmul}
produces the lower half of the carry-less product and \texttt{clmulh} produces the upper half
of the 2$\cdot$XLEN carry-less product.

\texttt{clmulr} produces bits 2$\cdot$XLEN$-2$:XLEN-1 of the 2$\cdot$XLEN carry-less product.
That means \texttt{clmulh} is equivalent to \texttt{clmulr} followed by a 1-bit right shift.
(The MSB of a \texttt{clmulh} result is always zero.) Another equivalent definition of
\texttt{clmulr} is that is \texttt{clmulr(a,b) := rev(clmul(rev(a), rev(b)))}. (The ``r''
in \texttt{clmulr} means reversed.)

Unlike {\tt mulh[[s]u]}, we add a *W variant of {\tt clmulh}. This is because we expect
some code to use 32-bit clmul intrisics, even on 64-bit architectures. For example in cases
where data is processed in 32-bit chunks.

\input{bextcref-clmul}

The classic applications for \texttt{clmul} are CRC~\cite{FastCRC,Wolf18A} and GCM, but more
applications exist, including the following examples.

There are obvious applications in hashing and pseudo random number generations. For
example, it has been reported that hashes based on carry-less multiplications can
outperform Google's CityHash~\cite{CLHASH}.

\texttt{clmul} of a number with itself inserts zeroes between each input bit. This can
be useful for generating Morton code~\cite{MortonCode}.

\texttt{clmul} of a number with -1 calculates the prefix XOR operation. This can
be useful for decoding gray codes.

Another application of XOR prefix sums calculated with \texttt{clmul} is
branchless tracking of quoted strings in high-performance parsers.~\cite{ParseJSON}

Carry-less multiply can also be used to implement Erasure code efficiently.~\cite{ClmulErasureCode}

SPARC introduced similar instructions (XMULX, XMULXHI) in SPARC T3 in 2010.~\cite{sparct3}

TI C6000 introduced a similar instruction (XORMPY) in C64x+.~\cite{c64xp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{CRC instructions (\texttt{crc32.[bhwd], crc32c.[bhwd]})}

\begin{rvb}
  RV32, RV64:
    crc32.b rd, rs
    crc32.h rd, rs
    crc32.w rd, rs
    crc32c.b rd, rs
    crc32c.h rd, rs
    crc32c.w rd, rs

  RV64 only:
    crc32.d rd, rs
    crc32c.d rd, rs
\end{rvb}

Unary CRC instructions that interpret the bits of rs1 as a CRC32/CRC32C state
and perform a polynomial reduction of that state shifted left by 8, 16, 32, or
64 bits.

The instructions return the new CRC32/CRC32C state.

The \texttt{crc32.w}/\texttt{crc32c.w} instructions are equivalent to executing
\texttt{crc32.h}/\texttt{crc32c.h} twice, and \texttt{crc32.h}/\texttt{crc32c.h}
instructions are equivalent to executing \texttt{crc32.b}/\texttt{crc32c.b}
twice.

All 8 CRC instructions operate on bit-reflected data.

\input{bextcref-crc}

Payload data must be XOR'ed into the LSB end of the state before executing the
CRC instruction. The following code demonstrates the use of \texttt{crc32.b}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  uint32_t crc32_demo(const uint8_t *p, int len)
  {
    uint32_t x = 0xffffffff;
    for (int i = 0; i < len; i++) {
      x = x ^ p[i];
      x = crc32_b(x);
    }
    return ~x;
  }
\end{verbatim}
\end{minipage}

In terms of binary polynomial arithmetic those instructions perform the operation
$$ \texttt{rd}'(x) = (\texttt{rs1}'(x) \cdot x^N) \; \textrm{mod} \; \{\texttt{1}, P'\}(x)\textrm, $$
with $N \in \{8, 16, 32, 64\}$,
$P = \texttt{0xEDB8\_8320}$ for CRC32 and $P = \texttt{0x82F6\_3B78}$ for CRC32C,
$a'$ denoting the XLEN bit reversal of $a$,
and $\{a, b\}$ denoting bit concatenation.
Note that for example for CRC32 $\{\texttt{1}, P'\} = \texttt{0x1\_04C1\_1DB7}$
on RV32 and $\{\texttt{1}, P'\} = \texttt{0x1\_04C1\_1DB7\_0000\_0000}$ on RV64.

These dedicated CRC instructions are meant for RISC-V implementations without fast multiplier
and therefore without fast \texttt{clmul[h]}. For implementations with fast \texttt{clmul[h]}
it is recommended to use the methods described in~\cite{FastCRC} and demonstrated in~\cite{Wolf18A}
that can process XLEN input bits using just one carry-less multiply for arbitrary CRC polynomials.

In applications where those methods are not applicable it is possible to emulate the dedicated CRC
instructions using two carry-less multiplies that implement a Barrett reduction. The following example
implements a replacement for \texttt{crc32.w} (RV32).

\begin{minipage}{\linewidth}
\begin{verbatim}
crc32_w:
  li t0, 0xF7011641
  li t1, 0xEDB88320
  clmul a0, a0, t0
  clmulr a0, a0, t1
  ret
\end{verbatim}
\end{minipage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bit-matrix operations (\texttt{bmatxor, bmator, bmatflip}, RV64 only)}

\begin{rvb}
  RV64 only:
    bmator rd, rs1, rs2
    bmatxor rd, rs1, rs2
    bmatflip rd, rs
\end{rvb}

These are 64-bit-only instruction that are not available on RV32. On RV128 they
ignore the upper half of operands and sign extend the results.

This instructions interpret a 64-bit value as 8x8 binary matrix.

\texttt{bmatxor} performs a matrix-matrix multiply with boolean AND as multiply
operator and boolean XOR as addition operator.

\texttt{bmator} performs a matrix-matrix multiply with boolean AND as multiply
operator and boolean OR as addition operator.

\texttt{bmatflip} is a unary operator that transposes the source matrix. It is
equivalent to \texttt{zip; zip; zip} on RV64.

Among other things, \texttt{bmatxor}/\texttt{bmator} can be used to perform
arbitrary permutations of bits within each byte (permutation matrix as 2nd
operand) or perform arbitrary permutations of bytes within a 64-bit word
(permutation matrix as 1st operand).

There are similar instructions in Cray XMT~\cite{CrayXMT}. The Cray X1
architecture even has a full 64x64 bit matrix multiply unit~\cite{CrayX1}.

The MMIX architecture has MOR and MXOR instructions with the same semantic.~\cite[p.~182f]{Knuth4A}

The x86 EVEX/VEX/SSE instruction GF2P8AFFINEQB is equivalent to {\tt bmatxor}.

\input{bextcref-bmat}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Ternary bit-manipulation instructions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conditional mix ({\tt cmix})}

\begin{rvb}
  RV32, RV64:
    cmix rd, rs2, rs1, rs3
\end{rvb}

(Note that the assembler syntax of {\tt cmix} has the {\tt rs2} argument first
to make assembler code more readable. But the reference C code code below uses
the ``architecturally correct'' argument order {\tt rs1, rs2, rs3}.)

The {\tt cmix rd, rs2, rs1, rs3} instruction selects bits from {\tt rs1} and {\tt rs3} based
on the bits in the control word {\tt rs2}.

\input{bextcref-cmix}

It is equivalent to the following sequence.

\begin{minipage}{\linewidth}
\begin{verbatim}
  and rd, rs1, rs2
  andn t0, rs3, rs2
  or rd, rd, t0
\end{verbatim}
\end{minipage}

Using {\tt cmix} a single butterfly stage can be implemented in only two
instructions. Thus, arbitrary bit-permutations can be implemented using only
18 instruction (32 bit) or 22 instructions (64 bits).

\subsection{Conditional move ({\tt cmov})}

\begin{rvb}
  RV32, RV64:
    cmov rd, rs2, rs1, rs3
\end{rvb}

(Note that the assembler syntax of {\tt cmov} has the {\tt rs2} argument first
to make assembler code more readable. But the reference C code code below uses
the ``architecturally correct'' argument order {\tt rs1, rs2, rs3}.)

The {\tt cmov rd, rs2, rs1, rs3} instruction selects {\tt rs1} if the control
word {\tt rs2} is non-zero, and {\tt rs3} if the control word is zero.

\input{bextcref-cmov}

The {\tt cmov} instruction helps avoiding branches, which can lead to better
performance, and helps with constant-time code as used in some cryptography
applications.

\subsection{Funnel shift ({\tt fsl}, {\tt fsr}, {\tt fsri})}

\begin{rvb}
  RV32, RV64:
    fsl  rd, rs1, rs3, rs2
    fsr  rd, rs1, rs3, rs2
    fsri rd, rs1, rs3, imm

  RV64 only:
    fslw  rd, rs1, rs3, rs2
    fsrw  rd, rs1, rs3, rs2
    fsriw rd, rs1, rs3, imm
\end{rvb}

(Note that the assembler syntax for funnel shifts has the {\tt rs2} argument
last to make assembler code more readable. But the reference C code code below
uses the ``architecturally correct'' argument order {\tt rs1, rs2, rs3}.)

The {\tt fsl rd, rs1, rs3, rs2} instruction creates a $2\cdot\textrm{XLEN}$ word
by concatenating rs1 and rs3 (with rs1 in the MSB half), rotate-left-shifts that
word by the amount indicated in the $log_2(\textrm{XLEN})+1$ LSB bits in rs2, and
then writes the MSB half of the result to rd.

The {\tt fsr rd, rs1, rs3, rs2} instruction creates a $2\cdot\textrm{XLEN}$ word
by concatenating rs1 and rs3 (with rs1 in the LSB half), rotate-right-shifts that
word by the amount indicated in the $log_2(\textrm{XLEN})+1$ LSB bits in rs2, and
then writes the LSB half of the result to rd.

\input{bextcref-fsl}

\input{bextcref-fsr}

A shift unit capable of either {\tt fsl} or {\tt fsr} is capable of performing all
the other shift functions, including the other funnel shift, with only minimal additional
logic.

For any values of {\tt A}, {\tt C}, and {\tt C}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  fsl(A, B, C) = fsr(A, -B, C)
\end{verbatim}
\end{minipage}

And for any values {\tt x} and $0 \le \texttt{shamt} < \texttt{XLEN}$:

\begin{minipage}{\linewidth}
\begin{verbatim}
  sll(x, shamt) == fsl(x, shamt, 0)
  srl(x, shamt) == fsr(x, shamt, 0)
  sra(x, shamt) == fsr(x, shamt, sext_x)
  slo(x, shamt) == fsl(x, shamt, ~0)
  sro(x, shamt) == fsr(x, shamt, ~0)
  ror(x, shamt) == fsr(x, shamt, x)
  rol(x, shamt) == fsl(x, shamt, x)
\end{verbatim}
\end{minipage}

Furthermore an RV64 implementation of either {\tt fsl} or {\tt fsr} is capable
of performing the *W versions of all shift operations with only a few gates
of additional control logic.

On RV128 there is no {\tt fsri} instruction. But there is {\tt fsriw} and {\tt fsrid}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Unsigned address calculation instructions}

Consider C code that's using unsigned 32-bit ints as array indices. For example:

\begin{minipage}{\linewidth}
\begin{verbatim}
  char addiwu_demo(char *p, unsigned int i) {
    return p[i-1];
  }

  int slliuw_demo(int *p, unsigned int i, unsigned int j) {
    return p[i^j];
  }
\end{verbatim}
\end{minipage}

In both cases the expression within {\tt p[\dots]} must overflow according to
32-bit arithmetic, then be zero-extended, and then this zero-extended result
must be used in the address calculation.

The instructions below make sure that no explicit {\tt zext.w} instruction
is needed in those cases, to make sure there is no systematic performance
penalty for code like shown above on RV64 compared to RV32.

\subsection{Add/sub with postfix zero-extend ({\tt addwu}, {\tt subwu}, {\tt addiwu})}

\begin{rvb}
  RV64:
    addwu rd, rs1, rs2
    subwu rd, rs1, rs2
    addiwu rd, rs1, imm
\end{rvb}

These instructions are identical to {\tt addw}, {\tt subw}, {\tt addiw},
except that bits XLEN-1:32 of the result are cleared after the addition. I.e.
these instructions zero-extend instead of sign-extend the 32-bit result.

\input{bextcref-addwu}

\subsection{Add/sub/shift with prefix zero-extend ({\tt addu.w}, {\tt subu.w}, {\tt slliu.w})}

\begin{rvb}
  RV64:
    addu.w rd, rs1, rs2
    subu.w rd, rs1, rs2
    slliu.w rd, rs1, imm
\end{rvb}

{\tt slliu.w} is identical to {\tt slli}, except that bits XLEN-1:32 of the
{\tt rs1} argument are cleared before the shift.

{\tt addu.w} and {\tt subu.w} are identical to {\tt add} and {\tt sub}, except
that bits XLEN-1:32 of the {\tt rs2} argument are cleared before the add/subtract.

\input{bextcref-slliuw}
\input{bextcref-adduw}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Opcode Encodings}
\label{opcodes}

This chapter contains proposed encodings for most of the instructions described
in this document. {\bf DO NOT IMPLEMENT THESE OPCODES YET.} We are trying to get
official opcodes assigned and will update this chapter soon with the official
opcodes.

The {\tt andn}, {\tt orn}, and {\tt xnor} instruction are encoded the same way
as {\tt and}, {\tt or}, and {\tt xor}, but with {\tt op[30]} set, mirroring the
encoding scheme used for {\tt add} and {\tt sub}.

All shift instructions use {\tt funct3=001} for left shifts and {\tt funct3=101}
for right shifts. GREV occupies the spot that would decode as SLA (arithmetic
left shift).

{\tt op[26]=1} selects funnel shifts. For funnel shifts {\tt op[30:29]} is part
if the 3rd operand and therefore unused for encoding the operation. For all other
shift operations {\tt op[26]=0}.

{\tt fsri} is also encoded with {\tt op[26]=1}, leaving a 6 bit immediate. The 7th
bit, that is necessary to perform a 128 bit funnel shift on RV64, can be
emulated by swapping rs1 and rs3.

There is no {\tt shfliw} instruction. The {\tt slliu.w} instruction occupies
the encoding slot that would be occupied by {\tt shfliw}.

On RV128 {\tt op[26]} contains the MSB of the immediate for the shift instructions.
Therefore there is no FSRI instruction on RV128. (But there is FSRIW/FSRID.)

\begin{minipage}{\linewidth}
\begin{verbatim}
         | SLL  SRL  SRA | GREV | SLO SRO | ROL ROR | FSL FSR
  op[30] |   0    0    1 |    1 |   0   0 |   1   1 |   -   -
  op[29] |   0    0    0 |    0 |   1   1 |   1   1 |   -   -
  op[26] |   0    0    0 |    0 |   0   0 |   0   0 |   1   1
  funct3 | 001  101  101 |  001 | 001 101 | 001 101 | 001 101
\end{verbatim}
\end{minipage}

Only an encoding for RORI exists, as ROLI can be implemented with RORI by negating
the immediate. Unary functions are encoded in the spot that would correspond to ROLI,
with the function encoded in the 5 LSB bits of the immediate.

The CRC instructions are encoded as unary instructions with {\tt op[24]} set. The
polynomial is selected via {\tt op[23]}, with {\tt op[23]=0} for CRC32 and
{\tt op[23]=1} for CRC32C. The width is selected with {\tt op[22:20]}, using
the same encoding as is used in {\tt funct3} for load/store operations.

{\tt cmix} and {\tt cmov} are encoded using the two remaining ternary operator
encodings in {\tt funct3=001} and {\tt funct3=101}. (There are two ternary
operator encodings per minor opcode using the {\tt op[26]=1} scheme for
marking ternary OPs.)

The single-bit instructions are also encoded within the shift opcodes, with
{\tt op[27]} set, and using {\tt op[30]} and {\tt op[29]} to select the operation:

\begin{minipage}{\linewidth}
\begin{verbatim}
         | SBSET  SBCLR  SBINV | SBEXT
  op[30] |     0      1      1 |     1
  op[29] |     1      0      1 |     0
  op[27] |     1      1      1 |     1
  funct3 |   001    001    001 |   101
\end{verbatim}
\end{minipage}

The remaining instructions are encoded within {\tt funct7=0000100} and
{\tt funct7=0000101}.

The {\tt funct7=0000101} block contains {\tt clmul[hr]},
{\tt min[u]}, and {\tt max[u]}.

The encoding of {\tt clmul, clmulr, clmulh} is identical to the encoding of
{\tt mulh, mulhsu, mulhu}, except that {\tt op[27]=1}.

The encoding of {\tt min[u]}/{\tt max[u]} uses {\tt funct3=100..111}. The
{\tt funct3} encoding matches {\tt op[31:29]} of the AMO min/max functions.

The remaining instructions are encoded within {\tt funct7=0000100}. The
shift-like {\tt shfl}/{\tt unshfl} instructions uses the same {\tt funct3}
values as the shift operations. {\tt bdep} and {\tt bext} are encoded in a
way so that {\tt funct3[2]} selects the ``direction'', similar to shift
operations.

{\tt bmat[x]or} use {\tt funct3=011} and {\tt funct3=111} in {\tt funct7=0000100}.

{\tt pack} occupies {\tt funct3=100} in {\tt funct7=0000100}.

{\tt addwu} and {\tt subwu} are encoded like {\tt addw} and {\tt subw}, except
that {\tt op[25]=1} and {\tt op[27]=1}.

{\tt addu.w} and {\tt subu.w} are encoded like {\tt addw} and {\tt subw}, except
that {\tt op[27]=1}.

{\tt addiwu} is encoded using {\tt funct3=100} (XOR) instead of {\tt funct3=000} in OP-32.

Finally, RV64 has {\tt *W} instructions for all bitmanip instructions, with the
following exceptions:

{\tt andn}, {\tt cmix}, {\tt cmov}, {\tt min[u]}, {\tt max[u]} have no {\tt *W}
variants because they already behave in the way a {\tt *W} instruction would
when presented with sign-exteded 32-bit arguments.

{\tt bmatflip}, {\tt bmatxor}, {\tt bmator} have no {\tt *W} variants because
they are 64-bit only instructions.

{\tt crc32.[bhwd]}, {\tt crc32c.[bhwd]} have no {\tt *W} variants because {\tt
crc32[c].w} is deemed sufficient.

There is no {\tt [un]shfliw}, as a perfect outer shuffle always preserves the
MSB bit, thus {\tt [un]shfli} preserves proper sign extension when the
upper bit in the control word is set. There's still {\tt [un]shflw} that
masks that upper control bit and sign-extends the output.

Relevant instruction encodings from the base ISA are included in the table below
and are marked with a {\tt *}.

% Opcodes:
% 0010011 OP-IMM
% 0110011 OP
% 0011011 OP-IMM-32
% 0111011 OP-32

\begin{minipage}{\linewidth}
\begin{verbatim}
|  3                   2                   1                    |
|1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0|
|---------------------------------------------------------------|
|    funct7   |   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R-type
|   rs3   | f2|   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R4-type
|          imm          |   rs1   |  f3 |    rd   |    opcode   |  I-type
|===============================================================|
|  0000000    |   rs2   |   rs1   | 111 |    rd   |   0110011   |  AND*
|  0000000    |   rs2   |   rs1   | 110 |    rd   |   0110011   |  OR*
|  0000000    |   rs2   |   rs1   | 100 |    rd   |   0110011   |  XOR*
|  0100000    |   rs2   |   rs1   | 111 |    rd   |   0110011   |  ANDN
|  0100000    |   rs2   |   rs1   | 110 |    rd   |   0110011   |  ORN
|  0100000    |   rs2   |   rs1   | 100 |    rd   |   0110011   |  XNOR
|---------------------------------------------------------------|
|  0000000    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SLL*
|  0000000    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  SRL*
|  0100000    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  GREV
|  0100000    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  SRA*
|  0010000    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SLO
|  0010000    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  SRO
|  0110000    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  ROL
|  0110000    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  ROR
|---------------------------------------------------------------|
|  0010100    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SBSET
|  0100100    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SBCLR
|  0110100    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SBINV
|  0100100    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  SBEXT
|---------------------------------------------------------------|
|  00000  |     imm     |   rs1   | 001 |    rd   |   0010011   |  SLLI*
|  00000  |     imm     |   rs1   | 101 |    rd   |   0010011   |  SRLI*
|  01000  |     imm     |   rs1   | 001 |    rd   |   0010011   |  GREVI
|  01000  |     imm     |   rs1   | 101 |    rd   |   0010011   |  SRAI*
|  00100  |     imm     |   rs1   | 001 |    rd   |   0010011   |  SLOI
|  00100  |     imm     |   rs1   | 101 |    rd   |   0010011   |  SROI
|  01100  |     imm     |   rs1   | 101 |    rd   |   0010011   |  RORI
|---------------------------------------------------------------|
|  00101  |     imm     |   rs1   | 001 |    rd   |   0010011   |  SBSETI
|  01001  |     imm     |   rs1   | 001 |    rd   |   0010011   |  SBCLRI
|  01101  |     imm     |   rs1   | 001 |    rd   |   0010011   |  SBINVI
|  01001  |     imm     |   rs1   | 101 |    rd   |   0010011   |  SBEXTI
|---------------------------------------------------------------|
|   rs3   | 11|   rs2   |   rs1   | 001 |    rd   |   0110011   |  CMIX
|   rs3   | 11|   rs2   |   rs1   | 101 |    rd   |   0110011   |  CMOV
|   rs3   | 10|   rs2   |   rs1   | 001 |    rd   |   0110011   |  FSL
|   rs3   | 10|   rs2   |   rs1   | 101 |    rd   |   0110011   |  FSR
|   rs3   |1|    imm    |   rs1   | 101 |    rd   |   0010011   |  FSRI
|---------------------------------------------------------------|
\end{verbatim}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{verbatim}
|  3                   2                   1                    |
|1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0|
|---------------------------------------------------------------|
|    funct7   |   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R-type
|   rs3   | f2|   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R4-type
|          imm          |   rs1   |  f3 |    rd   |    opcode   |  I-type
|===============================================================|
|  0110000    |  00000  |   rs1   | 001 |    rd   |   0010011   |  CLZ
|  0110000    |  00001  |   rs1   | 001 |    rd   |   0010011   |  CTZ
|  0110000    |  00010  |   rs1   | 001 |    rd   |   0010011   |  PCNT
|  0110000    |  00011  |   rs1   | 001 |    rd   |   0010011   |  BMATFLIP
|---------------------------------------------------------------|
|  0110000    |  10000  |   rs1   | 001 |    rd   |   0010011   |  CRC32.B
|  0110000    |  10001  |   rs1   | 001 |    rd   |   0010011   |  CRC32.H
|  0110000    |  10010  |   rs1   | 001 |    rd   |   0010011   |  CRC32.W
|  0110000    |  10011  |   rs1   | 001 |    rd   |   0010011   |  CRC32.D
|  0110000    |  11000  |   rs1   | 001 |    rd   |   0010011   |  CRC32C.B
|  0110000    |  11001  |   rs1   | 001 |    rd   |   0010011   |  CRC32C.H
|  0110000    |  11010  |   rs1   | 001 |    rd   |   0010011   |  CRC32C.W
|  0110000    |  11011  |   rs1   | 001 |    rd   |   0010011   |  CRC32C.D
|---------------------------------------------------------------|
|  0000101    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  CLMUL
|  0000101    |   rs2   |   rs1   | 010 |    rd   |   0110011   |  CLMULR
|  0000101    |   rs2   |   rs1   | 011 |    rd   |   0110011   |  CLMULH
|  0000101    |   rs2   |   rs1   | 100 |    rd   |   0110011   |  MIN
|  0000101    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  MAX
|  0000101    |   rs2   |   rs1   | 110 |    rd   |   0110011   |  MINU
|  0000101    |   rs2   |   rs1   | 111 |    rd   |   0110011   |  MAXU
|---------------------------------------------------------------|
|  0000100    |   rs2   |   rs1   | 001 |    rd   |   0110011   |  SHFL
|  0000100    |   rs2   |   rs1   | 101 |    rd   |   0110011   |  UNSHFL
|  0000100    |   rs2   |   rs1   | 010 |    rd   |   0110011   |  BDEP
|  0000100    |   rs2   |   rs1   | 110 |    rd   |   0110011   |  BEXT
|  0000100    |   rs2   |   rs1   | 100 |    rd   |   0110011   |  PACK
|  0000100    |   rs2   |   rs1   | 011 |    rd   |   0110011   |  BMATOR
|  0000100    |   rs2   |   rs1   | 111 |    rd   |   0110011   |  BMATXOR
|---------------------------------------------------------------|
|  000010   |    imm    |   rs1   | 001 |    rd   |   0010011   |  SHFLI
|  000010   |    imm    |   rs1   | 101 |    rd   |   0010011   |  UNSHFLI
|===============================================================|
|       immediate       |   rs1   | 000 |    rd   |   0011011   |  ADDIW*
|       immediate       |   rs1   | 100 |    rd   |   0011011   |  ADDIWU
|  00001  |     imm     |   rs1   | 001 |    rd   |   0011011   |  SLLIU.W
|---------------------------------------------------------------|
|  0000000    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  ADDW*
|  0100000    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  SUBW*
|  0000101    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  ADDWU
|  0100101    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  SUBWU
|  0000100    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  ADDU.W
|  0100100    |   rs2   |   rs1   | 000 |    rd   |   0111011   |  SUBU.W
|---------------------------------------------------------------|
\end{verbatim}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{verbatim}
|  3                   2                   1                    |
|1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0|
|---------------------------------------------------------------|
|    funct7   |   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R-type
|   rs3   | f2|   rs2   |   rs1   |  f3 |    rd   |    opcode   |  R4-type
|          imm          |   rs1   |  f3 |    rd   |    opcode   |  I-type
|===============================================================|
|  0000000    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SLLW*
|  0000000    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  SRLW*
|  0100000    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  GREVW
|  0100000    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  SRAW*
|  0010000    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SLOW
|  0010000    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  SROW
|  0110000    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  ROLW
|  0110000    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  RORW
|---------------------------------------------------------------|
|  0010100    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SBSETW
|  0100100    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SBCLRW
|  0110100    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SBINVW
|  0100100    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  SBEXTW
|---------------------------------------------------------------|
|  0000000    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SLLIW*
|  0000000    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SRLIW*
|  0100000    |   imm   |   rs1   | 001 |    rd   |   0011011   |  GREVIW
|  0100000    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SRAIW*
|  0010000    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SLOIW
|  0010000    |   imm   |   rs1   | 101 |    rd   |   0011011   |  SROIW
|  0110000    |   imm   |   rs1   | 101 |    rd   |   0011011   |  RORIW
|---------------------------------------------------------------|
|  0010100    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SBSETIW
|  0100100    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SBCLRIW
|  0110100    |   imm   |   rs1   | 001 |    rd   |   0011011   |  SBINVIW
|---------------------------------------------------------------|
|   rs3   | 10|   rs2   |   rs1   | 001 |    rd   |   0111011   |  FSLW
|   rs3   | 10|   rs2   |   rs1   | 101 |    rd   |   0111011   |  FSRW
|   rs3   | 10|   imm   |   rs1   | 101 |    rd   |   0011011   |  FSRIW
|---------------------------------------------------------------|
|  0110000    |  00000  |   rs1   | 001 |    rd   |   0011011   |  CLZW
|  0110000    |  00001  |   rs1   | 001 |    rd   |   0011011   |  CTZW
|  0110000    |  00010  |   rs1   | 001 |    rd   |   0011011   |  PCNTW
|---------------------------------------------------------------|
|  0000101    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  CLMULW
|  0000101    |   rs2   |   rs1   | 010 |    rd   |   0111011   |  CLMULRW
|  0000101    |   rs2   |   rs1   | 011 |    rd   |   0111011   |  CLMULHW
|---------------------------------------------------------------|
|  0000100    |   rs2   |   rs1   | 001 |    rd   |   0111011   |  SHFLW
|  0000100    |   rs2   |   rs1   | 101 |    rd   |   0111011   |  UNSHFLW
|  0000100    |   rs2   |   rs1   | 010 |    rd   |   0111011   |  BDEPW
|  0000100    |   rs2   |   rs1   | 110 |    rd   |   0111011   |  BEXTW
|  0000100    |   rs2   |   rs1   | 100 |    rd   |   0111011   |  PACKW
|---------------------------------------------------------------|
\end{verbatim}
\end{minipage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Future compressed instructions}

The RISC-V ISA has no dedicated instructions for bitwise inverse (\texttt{not}).
Instead \texttt{not} is implemented as \texttt{xori\ rd,\ rs,\ -1} and
\texttt{neg} is implemented as \texttt{sub\ rd,\ x0,\ rs}.

In bitmanipulation code \texttt{not} is a very common operation. But there is
no compressed encoding for those operation because there is no \texttt{c.xori}
instruction.

On RV64 (and RV128) {\tt zext.w} and {\tt zext.d} ({\tt pack} and {\tt packw})
are commonly used to zero-extend unsigned values $<$XLEN.

It presumably would make sense for a future revision of the ``C'' extension to
include compressed opcodes for those instructions.

An encoding with the constraint \texttt{rd $=$ rs} would fit nicely in the
reserved space in \texttt{c.addi16sp/c.lui}.

\begin{table}[h]
\begin{small}
\begin{center}
\begin{tabular}{p{0in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}p{0.05in}l}
& & & & & & & & & & \\
                      &
\instbit{15} &
\instbit{14} &
\instbit{13} &
\multicolumn{1}{c}{\instbit{12}} &
\instbit{11} &
\instbit{10} &
\instbit{9} &
\instbit{8} &
\instbit{7} &
\instbit{6} &
\multicolumn{1}{c}{\instbit{5}} &
\instbit{4} &
\instbit{3} &
\instbit{2} &
\instbit{1} &
\instbit{0} \\
\cline{2-17}

&
\multicolumn{3}{|c|}{011} &
\multicolumn{1}{c|}{nzimm[9]} &
\multicolumn{5}{c|}{2} &
\multicolumn{5}{c|}{nzimm[4$\vert$6$\vert$8:7$\vert$5]} &
\multicolumn{2}{c|}{01} & C.ADDI16SP {\em \tiny (\sout{RES, nzimm=0})} \\
\cline{2-17}

&
\multicolumn{3}{|c|}{011} &
\multicolumn{1}{c|}{nzimm[17]} &
\multicolumn{5}{c|}{rd$\neq$$\{0,2\}$} &
\multicolumn{5}{c|}{nzimm[16:12]} &
\multicolumn{2}{c|}{01} & C.LUI {\em \tiny (\sout{RES, nzimm=0}; HINT, rd=0)} \\
\cline{2-17}

&
\multicolumn{3}{|c|}{011} &
\multicolumn{1}{c|}{0} &
\multicolumn{2}{c|}{00} &
\multicolumn{3}{c|}{rs1$'$/rd$'$} &
\multicolumn{5}{c|}{0} &
\multicolumn{2}{c|}{01} & C.NOT \\
\cline{2-17}

&
\multicolumn{3}{|c|}{011} &
\multicolumn{1}{c|}{0} &
\multicolumn{2}{c|}{01} &
\multicolumn{3}{c|}{rs1$'$/rd$'$} &
\multicolumn{5}{c|}{0} &
\multicolumn{2}{c|}{01} & C.ZEXT.W {\em \tiny (RV64/128)} \\
\cline{2-17}

&
\multicolumn{3}{|c|}{011} &
\multicolumn{1}{c|}{0} &
\multicolumn{2}{c|}{11} &
\multicolumn{3}{c|}{rs1$'$/rd$'$} &
\multicolumn{5}{c|}{0} &
\multicolumn{2}{c|}{01} & C.ZEXT.D {\em \tiny (RV128)} \\
\cline{2-17}

\end{tabular}
\end{center}
\end{small}
\end{table}

The entire RVC encoding space is $15.585$~bits wide, the remaining reserved
encoding space in RVC is $11.155$~bits wide, not including space that is only
reserved on RV32/RV64. This means that above encoding would use $0.0065\%$ of
the RVC encoding space, or $1.4\%$ of the remaining reserved RVC encoding
space. Preliminary experiments have shown that NOT instructions alone make up
approximately $1\%$ of bitmanipulation code size.~\cite{Wolf17A}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Future 64-bit instructions for bit-field extract and place}

When instruction encodings for instructions $>$32-bit are defined, a {\bf Zbf} (bit-field)
extension should be considered that defines the following {\it bit-field extract and place}
instructions.

\begin{rvb}
  RV32, RV64:
    bfxp  rd, rs1, rs2, src_off, src_len, dst_off, dst_len
    bfxpu rd, rs1, rs2, src_off, src_len, dst_off, dst_len

  RV64 only:
    bfxpw  rd, rs1, rs2, src_off, src_len, dst_off, dst_len
    bfxpuw rd, rs1, rs2, src_off, src_len, dst_off, dst_len
\end{rvb}

These instructions extract {\tt src\_len} bits at offset {\tt src\_off} from {\tt rs1},
and place them in the field of {\tt dst\_len} bits at offset {\tt dst\_off} in the
value from {\tt rs2}. {\tt bfxp} sign-extends if {\tt dst\_len}$>${\tt src\_len},
and {\tt bfxpu} zero-extends. When {\tt src\_len == 0} then {\tt bfxp} sets bits
in the output and {\tt bfxpu} clears bits. {\tt dst\_len == 0} encodes for
{\tt dst\_len == XLEN}. When {\tt src\_len}$+${\tt src\_off} $>$ XLEN
or {\tt dst\_len}$+${\tt dst\_off} $>$ XLEN then the bit-field wraps around.

\input{bextcref-bfxp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Micro architectural considerations and macro-op fusion for bit-manipulation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fast {\tt MUL}, {\tt MULH}, {\tt MULHSU}, {\tt MULHU}}

A lot of bit manipulation code depends on ``multiply with magic number''-tricks. Often those
tricks need the upper half of the $2 \cdot \textrm{XLEN}$ product. Therefore decent performance
for the \texttt{MUL} and especially \texttt{MULH[[S]U]} instructions is important for fast
bit manipulation code.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fused load-immediate sequences}

Bit manipulation code, even more than other code, requires a lot of ``magic numbers'',
bitmasks, and other (usually large) constants. On some microarchitectures those
can easily be loaded from a nearby data section using load instructions. On other
microarchitectures however this comes at a high cost, and it is more efficient
to load immediates using a sequence of instructions.

Loading a 32-bit constant:

\begin{minipage}{\linewidth}
\begin{verbatim}
  lui rd, imm
  addi rd, rd, imm
\end{verbatim}
\end{minipage}

On RV64 a 64 bit constant can be loaded by loading two 32-bit constants and combining them
with a {\tt PACK} instruction:

\begin{minipage}{\linewidth}
\begin{verbatim}
  lui tmp, imm
  addi tmp, tmp, imm
  lui rd, imm
  addi rd, rd, imm
  pack rd, rd, tmp
\end{verbatim}
\end{minipage}

(Without the temporary register and without the {\tt PACK} instruction more complex/diverse
sequences are used to load 64-bit immediates. But the {\tt PACK} instruction streamlines
the pattern and thus simplifies macro-op fusion.)

A 32-bit core should be capable of fusing the {\tt lui}+{\tt addi} pattern.

In addition to that, a 64 bit core may consider fusing the following sequences as well:

\begin{minipage}{\linewidth}
\begin{verbatim}
  lui rd, imm
  addi rd, rd, imm
  pack rd, rd, rs2

  lui rd, imm
  pack rd, rd, rs2

  addi rd, zero, imm
  pack rd, rd, rs2
\end{verbatim}
\end{minipage}

Furthermore, a core may consider fusing 32-bit immediate loads with any ALU
instruction, not just {\tt pack}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  lui rd, imm
  addi rd, rd, imm
  alu_op rd, rd, rs2

  lui rd, imm
  alu_op rd, rd, rs2

  addi rd, zero, imm
  alu_op rd, rd, rs2
\end{verbatim}
\end{minipage}

And finally, a 64-bit core should fuse sequences with {\tt addiwu} as well as
{\tt addi}, for loading unsigned 32-bit numbers that have their MSB set. This is
often the case with masks in bit manipulation code.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fused {\tt *-not} sequences}

Preliminary experiments have shown that NOT instructions make up approximately
$1\%$ of bitmanipulation code size, more when looking at dynamic instruction count.~\cite{Wolf17A}

Therefore it makes sense to fuse NOT instructions with other ALU instructions, if possible.

The most important form of NOT fusion is postfix fusion:

\begin{minipage}{\linewidth}
\begin{verbatim}
  alu_op rd, rs1, rs2
  not rd, rd
\end{verbatim}
\end{minipage}

A future compressed NOT instruction would help keeping those fused sequences short.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fused {\tt *-srli} and {\tt *-srai} sequences}

Pairs of left and right shifts are common operations for extracting a bit field.

To extract the contiguous bit field starting at {\tt pos} with length {\tt len}
from {\tt rs} (with $\texttt{pos}>0$, $\texttt{len}>0$, and
$\texttt{pos}+\texttt{len}\le\textrm{XLEN}$):

\begin{minipage}{\linewidth}
\begin{verbatim}
  slli rd, rs, (XLEN-len-pos)
  srli rd, rd, (XLEN-len)
\end{verbatim}
\end{minipage}

Using \texttt{srai} instead of \texttt{srli} will sign-extend the extracted bit-field.

Similarly, placing a bit field with length {\tt len} at the position {\tt pos}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  slli rd, rs, (XLEN-len-pos)
  srli rd, rd, (XLEN-len)
\end{verbatim}
\end{minipage}

If possible, an implementation should fuse the following macro ops:

\begin{minipage}{\linewidth}
\begin{verbatim}
  alu_op rd, rs1, rs2
  srli rd, rd, imm

  alu_op rd, rs1, rs2
  srai rd, rd, imm
\end{verbatim}
\end{minipage}

Note that the postfix right shift instruction can use a compressed encoding,
yielding a 48-bit fused instruction if {\tt alu\_op} is a 32-bit instruction.

For generating masks, i.e. constants with one continous run of 1 bits, a sequence
like the following can be used that would utilize postfix fusion of right shifts:

\begin{minipage}{\linewidth}
\begin{verbatim}
  sroi rd, zero, len
  c.srli rd, (XLEN-len-pos)
\end{verbatim}
\end{minipage}

This can be a useful sequence on RV64, where loading an arbitrary 64-bit constant would usually
require at least 96 bits (using \texttt{c.ld}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fused sequences for logic operations}

RISC-V has dedicated instructions for branching on equal/not-equal. But C code
such as the following would require set-equal and set-not-equal instructions, similar
to {\tt slt}.

\begin{minipage}{\linewidth}
\begin{verbatim}
  int is_equal = (a == b);
  int is_noteq = (c != d);
\end{verbatim}
\end{minipage}

Those can be implemented using the following fuse-able sequences:

\begin{minipage}{\linewidth}
\begin{verbatim}
  sub rd, rs1, rs2
  sltui rd, rd, 1

  sub rd, rs1, rs2
  sltu rd, zero, rd
\end{verbatim}
\end{minipage}

Likewise for logic OR:

\begin{minipage}{\linewidth}
\begin{verbatim}
  int logic_or  = (c || d);

  or rd, rs1, rs2
  sltu rd, zero, rd
\end{verbatim}
\end{minipage}

And for logic AND, if {\tt rd == rs1}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  int logic_and  = (c && d);

  beq rd, zero, skip_sltu
  sltu rd, zero, rs2
skip_sltu:
\end{verbatim}
\end{minipage}

Note that the first instruction can be compressed in all four cases if {\tt rd == rs1}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Fused ternary ALU sequences}

Architectures with support for ternary operations may want to support fusing two ALU operations.

\begin{minipage}{\linewidth}
\begin{verbatim}
  alu_op rd, ...
  alu_op rd, rd, ...
\end{verbatim}
\end{minipage}

This would be a postfix-fusion pattern, extending the postfix shift-right
fusion described in the previous section.

Candidates for this kind of postfix fusion would be simple ALU operations, specifically
AND/OR/XOR/ADD/SUB and ANDI/ORI/XORI/ADDI/SUBI.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Pseudo-ops for fused sequences}

Assembler pseudo-ops for {\tt not} postfix fusion:

\begin{minipage}{\linewidth}
\begin{verbatim}
  nand rd, rs1, rs2        ->   and rd, rs1, rs2; not rd, rd
  nor  rd, rs1, rs2        ->   or  rd, rs1, rs2; not rd, rd
\end{verbatim}
\end{minipage}

Assembler bitfield pseudo-ops for {\tt sr[la]i} postfix fusion:

\begin{minipage}{\linewidth}
\begin{verbatim}
  bfext  rd, rs, len, pos    ->   slli rd, rs, (XLEN-len-pos); srai rd, rd, (XLEN-len)
  bfextu rd, rs, len, pos    ->   slli rd, rs, (XLEN-len-pos); srli rd, rd, (XLEN-len)
  bfmak  rd, len, pos        ->   sroi rd, zero, len; srli rd, rd, (XLEN-len-pos)
\end{verbatim}
\end{minipage}

The names {\tt bfext}, {\tt bfextu}, and {\tt bfmak} are borrowed from m88k, that had
dedicated instructions of those names (without {\tt bf}-prefix) with equivalent semantics.~\cite[p.~3-28]{m88k}

Sign-extending bytes and half-words are special cases of {\tt bfext}:

\begin{minipage}{\linewidth}
\begin{verbatim}
  sext.b rd, rs   ->   slli rd, rs, (XLEN-8);  srai rd, rd, (XLEN-8)
  sext.h rd, rs   ->   slli rd, rs, (XLEN-16); srai rd, rd, (XLEN-16)
\end{verbatim}
\end{minipage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[h]
\begin{center}
\begin{tabular}{l|cc|ccc|}
& \multicolumn{2}{c|}{RV32} & \multicolumn{3}{c|}{RV64} \\
Instruction & {\tt \_rv\_*} & {\tt \_rv32\_*} & {\tt \_rv\_*} & {\tt \_rv32\_*} & {\tt \_rv64\_*} \\
\hline
{\tt clz      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt ctz      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt pcnt     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt pack     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt min      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt minu     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt max      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt maxu     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt sbset    } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt sbclr    } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt sbinv    } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt sbext    } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt sll      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt srl      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt sra      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt slo      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt sro      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt rol      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt ror      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt grev     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt shfl     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt unshfl   } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt bext     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt bdep     } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt clmul    } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt clmulh   } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt clmulr   } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt bmatflip } &           &           & \ding{52} &           & \ding{52} \\
{\tt bmator   } &           &           & \ding{52} &           & \ding{52} \\
{\tt bmatxor  } &           &           & \ding{52} &           & \ding{52} \\
\hline
{\tt fsl      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
{\tt fsr      } & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} \\
\hline
{\tt cmix     } & \ding{52} &           & \ding{52} &           &           \\
{\tt cmov     } & \ding{52} &           & \ding{52} &           &           \\
\hline
{\tt crc32\_b } & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32\_h } & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32\_w } & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32\_d } &           &           & \ding{52} &           &           \\
\hline
{\tt crc32c\_b} & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32c\_h} & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32c\_w} & \ding{52} &           & \ding{52} &           &           \\
{\tt crc32c\_d} &           &           & \ding{52} &           &           \\
\end{tabular}
\end{center}
\caption{C intrinsics defined in {\tt <rvintrin.h>}}
\label{rvintrin}
\end{table}

\section{C intrinsics via {\tt <rvintrin.h>}}

A C header file {\tt <rvintrin.h>} is provided that contains assembler
templates for directly creating assembler instructions from C code.

The header defines {\tt \_rv\_*(...)} functions that operate on the {\tt long}
data type, {\tt \_rv32\_*(...)} functions that operate on the {\tt int32\_t}
data type, and {\tt \_rv64\_*(...)} functions that operate on the {\tt
int64\_t} data type. The {\tt \_rv64\_*(...)} functions are only available on
RV64. See table~\ref{rvintrin} for a complete list of intrinsics defined in
{\tt <rvintrin.h>}.

Usage example:

\begin{minipage}{\linewidth}
\begin{verbatim}
  #include <rvintrin.h>

  int find_nth_set_bit(unsigned int value, int cnt) {
    return _rv32_ctz(_rv32_bdep(1 << cnt, value));
  }
\end{verbatim}
\end{minipage}

Defining {\tt RVINTRIN\_EMULATE} before including {\tt <rvintrin.h>} will
define plain C functions that emulate the behavior of the RISC-V instructions.
This is useful for testing software on non-RISC-V platforms.
